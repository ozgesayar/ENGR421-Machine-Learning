{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENGR421 HW6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ã–ZGE SAYAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxopt as cvx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.spatial.distance as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data into memory\n",
    "data_set_images = np.genfromtxt(\"hw06_data_set_images.csv\", delimiter = \",\")\n",
    "data_set_labels = np.genfromtxt(\"hw06_data_set_labels.csv\", delimiter = \",\")\n",
    "\n",
    "#define train data (25 x 5)\n",
    "trainingdata_images = data_set_images[:1000]\n",
    "trainingdata_labels = data_set_labels[:1000]       \n",
    "    \n",
    "#define test data (14 x 5)\n",
    "testdata_images = data_set_images[1000:]   \n",
    "testdata_labels = data_set_labels[1000:]  \n",
    "\n",
    "# get number of samples and number of features\n",
    "N_train_images = len(trainingdata_images)\n",
    "N_test_images = len(testdata_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Color Histograms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.86479592 0.00127551 0.         0.00255102 0.        ]\n",
      " [0.66836735 0.         0.00127551 0.00127551 0.        ]\n",
      " [0.66454082 0.00637755 0.00382653 0.00765306 0.00892857]\n",
      " [0.65816327 0.00765306 0.00892857 0.00127551 0.00382653]\n",
      " [0.5625     0.00255102 0.00255102 0.00127551 0.        ]]\n",
      "[[0.68239796 0.00255102 0.00127551 0.00127551 0.00127551]\n",
      " [0.69770408 0.01658163 0.00510204 0.00382653 0.01020408]\n",
      " [0.73341837 0.02678571 0.01530612 0.00510204 0.00637755]\n",
      " [0.63903061 0.00892857 0.00255102 0.00127551 0.        ]\n",
      " [0.75382653 0.00765306 0.00127551 0.00127551 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "bin_calculator = np.zeros((N_train_images, 64)) \n",
    "bins = np.zeros((N_train_images, 784))\n",
    "bin_loc = np.zeros((N_train_images, 784))\n",
    "for i in range (N_train_images):\n",
    "    for j in range (784):\n",
    "        bin_loc = np.floor(trainingdata_images[i,j]/4).astype(int) \n",
    "        bin_calculator[i, bin_loc] = bin_calculator[i, bin_loc] + 1 \n",
    "        H_train = bin_calculator / 784\n",
    "                \n",
    "print(H_train[0:5,0:5])\n",
    "\n",
    "bin_calculator = np.zeros((N_test_images, 64))\n",
    "bins = np.zeros((N_test_images, 784))\n",
    "bin_loc = np.zeros((N_test_images, 784))\n",
    "for i in range (N_test_images):\n",
    "    for j in range (784):\n",
    "        bin_loc = np.floor(testdata_images[i,j]/4).astype(int) \n",
    "        bin_calculator[i, bin_loc] = bin_calculator[i, bin_loc] + 1 \n",
    "        H_test = bin_calculator / 784\n",
    "                \n",
    "print(H_test[0:5,0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram Intersection Kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.72321429 0.77040816 ... 0.9005102  0.72704082 0.7869898 ]\n",
      " [0.72321429 1.         0.73086735 ... 0.71173469 0.80739796 0.79846939]\n",
      " [0.77040816 0.73086735 1.         ... 0.76785714 0.78316327 0.78954082]\n",
      " ...\n",
      " [0.9005102  0.71173469 0.76785714 ... 1.         0.72576531 0.78826531]\n",
      " [0.72704082 0.80739796 0.78316327 ... 0.72576531 1.         0.86479592]\n",
      " [0.7869898  0.79846939 0.78954082 ... 0.78826531 0.86479592 1.        ]]\n",
      "[[0.77806122 0.80867347 0.82142857 ... 0.75892857 0.86862245 0.90688776]\n",
      " [0.79464286 0.76403061 0.84566327 ... 0.80357143 0.83163265 0.88647959]\n",
      " [0.8380102  0.74362245 0.85714286 ... 0.83673469 0.77806122 0.84183673]\n",
      " ...\n",
      " [0.7002551  0.75       0.76403061 ... 0.70153061 0.84183673 0.84311224]\n",
      " [0.58673469 0.78443878 0.64413265 ... 0.5880102  0.70790816 0.67984694]\n",
      " [0.90688776 0.75765306 0.7997449  ... 0.89540816 0.76913265 0.83418367]]\n"
     ]
    }
   ],
   "source": [
    "def intersection_kernel(hi,hj):\n",
    "    return np.sum(min(hi[l],hj[l]) for l in range(64))\n",
    "\n",
    "K_train = np.zeros((N_train_images, N_train_images))\n",
    "for i in range (N_train_images):\n",
    "    for j in range (N_train_images):\n",
    "        K_train[i][j] = intersection_kernel(H_train[i],H_train[j])\n",
    "        \n",
    "K_test = np.zeros((N_test_images, N_test_images))\n",
    "for i in range (N_test_images):\n",
    "    for j in range (N_train_images):\n",
    "        K_test[i][j] = intersection_kernel(H_test[i], H_train[j])\n",
    "        \n",
    "print(K_train)\n",
    "print(K_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def svm_classifier(C):\n",
    "    X_train = trainingdata_images \n",
    "    y_train = trainingdata_labels\n",
    "    X_test = testdata_images \n",
    "    y_test = testdata_labels\n",
    "\n",
    "    s = 1\n",
    "    C = 10\n",
    "    epsilon = 0.001\n",
    "\n",
    "    yyK = np.matmul(y_train[:,None], y_train[None,:]) * K_train\n",
    "\n",
    "    P = cvx.matrix(yyK)\n",
    "    q = cvx.matrix(-np.ones((N_train_images, 1)))\n",
    "    G = cvx.matrix(np.vstack((-np.eye(N_train_images), np.eye(N_train_images))))\n",
    "    h = cvx.matrix(np.vstack((np.zeros((N_train_images, 1)), C * np.ones((N_train_images, 1)))))\n",
    "    A = cvx.matrix(1.0 * y_train[None,:])\n",
    "    b = cvx.matrix(0.0)\n",
    "\n",
    "\n",
    "    # use cvxopt library to solve QP problems\n",
    "    result = cvx.solvers.qp(P, q, G, h, A, b)\n",
    "    alpha = np.reshape(result[\"x\"], N_train_images)\n",
    "    alpha[alpha < C * epsilon] = 0\n",
    "    alpha[alpha > C * (1 - epsilon)] = C\n",
    "\n",
    "\n",
    "    # find bias parameter\n",
    "    support_indices, = np.where(alpha != 0)\n",
    "    active_indices, = np.where(np.logical_and(alpha != 0, alpha < C))\n",
    "    w0 = np.mean(y_train[active_indices] * (1 - np.matmul(yyK[np.ix_(active_indices, support_indices)], alpha[support_indices])))\n",
    "    \n",
    "    return (w0, alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train      -1.0   1.0\n",
      "y_predicted            \n",
      "-1            484     9\n",
      " 1              9   498\n",
      "y_test       -1.0   1.0\n",
      "y_predicted            \n",
      "-1            466    25\n",
      " 1             37   472\n"
     ]
    }
   ],
   "source": [
    "def prediction(K_train, K_test):\n",
    "    \n",
    "    w0, alpha = svm_classifier(C)\n",
    "    f_predicted_train = np.matmul(K_train, y_train[:,None] * alpha[:,None]) + w0\n",
    "    y_predicted_train = 2 * (f_predicted_train > 0.0) - 1\n",
    "    f_predicted_test = np.matmul(K_test, y_train[:,None] * alpha[:,None]) + w0\n",
    "    y_predicted_test = 2 * (f_predicted_test > 0.0) - 1\n",
    "    \n",
    "    return(y_predicted_train,y_predicted_test)\n",
    "    \n",
    "\n",
    "confusion_matrix_train = pd.crosstab(np.reshape(y_predicted_train, N_train_images), y_train,\n",
    "                               rownames = [\"y_predicted\"], colnames = [\"y_train\"])\n",
    "print(confusion_matrix_train)\n",
    "\n",
    "\n",
    "\n",
    "confusion_matrix_test = pd.crosstab(np.reshape(y_predicted_test, N_test_images), y_test,\n",
    "                               rownames = [\"y_predicted\"], colnames = [\"y_test\"])\n",
    "print(confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.0887e+03 -6.1913e+04  1e+05  5e-01  5e-14\n",
      " 1:  1.2396e+03 -1.1654e+04  1e+04  3e-14  5e-14\n",
      " 2: -4.1568e+02 -3.9854e+03  4e+03  1e-14  5e-14\n",
      " 3: -8.3426e+02 -2.5760e+03  2e+03  2e-14  5e-14\n",
      " 4: -1.0562e+03 -1.7960e+03  7e+02  6e-14  5e-14\n",
      " 5: -1.2018e+03 -1.4485e+03  2e+02  7e-15  6e-14\n",
      " 6: -1.2586e+03 -1.3270e+03  7e+01  2e-14  7e-14\n",
      " 7: -1.2782e+03 -1.2901e+03  1e+01  7e-14  7e-14\n",
      " 8: -1.2826e+03 -1.2831e+03  5e-01  4e-14  7e-14\n",
      " 9: -1.2828e+03 -1.2828e+03  1e-02  4e-15  7e-14\n",
      "10: -1.2828e+03 -1.2828e+03  2e-04  3e-14  7e-14\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-4fe22ddf1ed2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0my_predicted_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_predicted_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mtraining_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predicted_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mtest_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predicted_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "C = [10**-1, 10**-.5, 10**0, 10**.5, 10**1, 10**1.5, 10**2, 10**2.5, 10**3]\n",
    "\n",
    "training_scores = []\n",
    "test_scores = []\n",
    "\n",
    "def accuracy(y_predicted, y_truth):\n",
    "    score = 0.0\n",
    "    for i in range(len(y_truth)):\n",
    "        score += 1\n",
    "    accuracy_score = float(score / len(y_truth))\n",
    "    return accuracy_score\n",
    "\n",
    "for c in C:\n",
    "    y_predicted_train, y_predicted_test = prediction(K_train, K_test)\n",
    "    training_scores.append(accuracy(y_predicted_train, y_train))\n",
    "    test_scores.append(accuracy(y_predicted_test, y_test))\n",
    "    \n",
    "x_axis_vals = [\"10^-1\", \"10^-0.5\", \"1\", \"10^0.5\", \"10^1\", \"10^1.5\", \"10^2\", \"10^2.5\", \"10^3\"]\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(x_axis_vals, training_scores, \"-ob\", markersize=4, label='training')\n",
    "plt.plot(x_axis_vals, test_scores, \"-or\", markersize=4, label='test')\n",
    "plt.xlabel(\"Regularization parameter (C)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
