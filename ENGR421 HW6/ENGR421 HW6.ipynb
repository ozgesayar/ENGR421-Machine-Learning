{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENGR421 HW6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ã–ZGE SAYAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxopt as cvx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.spatial.distance as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data into memory\n",
    "data_set_images = np.genfromtxt(\"hw06_data_set_images.csv\", delimiter = \",\")\n",
    "data_set_labels = np.genfromtxt(\"hw06_data_set_labels.csv\", delimiter = \",\")\n",
    "\n",
    "#define train data (25 x 5)\n",
    "trainingdata_images = data_set_images[:1000]\n",
    "trainingdata_labels = data_set_labels[:1000]       \n",
    "    \n",
    "#define test data (14 x 5)\n",
    "testdata_images = data_set_images[1000:]   \n",
    "testdata_labels = data_set_labels[1000:]  \n",
    "\n",
    "# get number of samples and number of features\n",
    "N_train_images = len(trainingdata_images)\n",
    "N_test_images = len(testdata_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Color Histograms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_calculator = np.zeros((N_train_images, 64)) \n",
    "bins = np.zeros((N_train_images, 784))\n",
    "bin_loc = np.zeros((N_train_images, 784))\n",
    "for i in range (N_train_images):\n",
    "    for j in range (784):\n",
    "        bin_loc = np.floor(trainingdata_images[i,j]/4).astype(int) \n",
    "        bin_calculator[i, bin_loc] = bin_calculator[i, bin_loc] + 1 \n",
    "        H_train = bin_calculator / 784\n",
    "                \n",
    "print(H_train[0:5,0:5])\n",
    "\n",
    "bin_calculator = np.zeros((N_test_images, 64))\n",
    "bins = np.zeros((N_test_images, 784))\n",
    "bin_loc = np.zeros((N_test_images, 784))\n",
    "for i in range (N_test_images):\n",
    "    for j in range (784):\n",
    "        bin_loc = np.floor(testdata_images[i,j]/4).astype(int) \n",
    "        bin_calculator[i, bin_loc] = bin_calculator[i, bin_loc] + 1 \n",
    "        H_test = bin_calculator / 784\n",
    "                \n",
    "print(H_test[0:5,0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram Intersection Kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_kernel(hi,hj):\n",
    "    return np.sum(min(hi[l],hj[l]) for l in range(64))\n",
    "\n",
    "K_train = np.zeros((N_train_images, N_train_images))\n",
    "for i in range (N_train_images):\n",
    "    for j in range (N_train_images):\n",
    "        K_train[i][j] = intersection_kernel(H_train[i],H_train[j])\n",
    "        \n",
    "K_test = np.zeros((N_test_images, N_test_images))\n",
    "for i in range (N_test_images):\n",
    "    for j in range (N_train_images):\n",
    "        K_test[i][j] = intersection_kernel(H_test[i], H_train[j])\n",
    "        \n",
    "print(K_train)\n",
    "print(K_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def svm_classifier(C):\n",
    "    X_train = trainingdata_images \n",
    "    y_train = trainingdata_labels\n",
    "    X_test = testdata_images \n",
    "    y_test = testdata_labels\n",
    "\n",
    "    s = 1\n",
    "    C = 10\n",
    "    epsilon = 0.001\n",
    "\n",
    "    yyK = np.matmul(y_train[:,None], y_train[None,:]) * K_train\n",
    "\n",
    "    P = cvx.matrix(yyK)\n",
    "    q = cvx.matrix(-np.ones((N_train_images, 1)))\n",
    "    G = cvx.matrix(np.vstack((-np.eye(N_train_images), np.eye(N_train_images))))\n",
    "    h = cvx.matrix(np.vstack((np.zeros((N_train_images, 1)), C * np.ones((N_train_images, 1)))))\n",
    "    A = cvx.matrix(1.0 * y_train[None,:])\n",
    "    b = cvx.matrix(0.0)\n",
    "\n",
    "\n",
    "    # use cvxopt library to solve QP problems\n",
    "    result = cvx.solvers.qp(P, q, G, h, A, b)\n",
    "    alpha = np.reshape(result[\"x\"], N_train_images)\n",
    "    alpha[alpha < C * epsilon] = 0\n",
    "    alpha[alpha > C * (1 - epsilon)] = C\n",
    "\n",
    "\n",
    "    # find bias parameter\n",
    "    support_indices, = np.where(alpha != 0)\n",
    "    active_indices, = np.where(np.logical_and(alpha != 0, alpha < C))\n",
    "    w0 = np.mean(y_train[active_indices] * (1 - np.matmul(yyK[np.ix_(active_indices, support_indices)], alpha[support_indices])))\n",
    "    \n",
    "    return (w0, alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(K_train, K_test, C):\n",
    "    \n",
    "    w0, alpha = svm_classifier(C)\n",
    "    f_predicted_train = np.matmul(K_train, y_train[:,None] * alpha[:,None]) + w0\n",
    "    y_predicted_train = 2 * (f_predicted_train > 0.0) - 1\n",
    "    f_predicted_test = np.matmul(K_test, y_train[:,None] * alpha[:,None]) + w0\n",
    "    y_predicted_test = 2 * (f_predicted_test > 0.0) - 1\n",
    "    \n",
    "    return(y_predicted_train,y_predicted_test)\n",
    "    \n",
    "\n",
    "confusion_matrix_train = pd.crosstab(np.reshape(y_predicted_train, N_train_images), y_train,\n",
    "                               rownames = [\"y_predicted\"], colnames = [\"y_train\"])\n",
    "print(confusion_matrix_train)\n",
    "\n",
    "\n",
    "\n",
    "confusion_matrix_test = pd.crosstab(np.reshape(y_predicted_test, N_test_images), y_test,\n",
    "                               rownames = [\"y_predicted\"], colnames = [\"y_test\"])\n",
    "print(confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [10**-1, 10**-.5, 10**0, 10**.5, 10**1, 10**1.5, 10**2, 10**2.5, 10**3]\n",
    "\n",
    "training_scores = []\n",
    "test_scores = []\n",
    "\n",
    "def score(y_predicted, y_truth):\n",
    "    score = 0.0\n",
    "    for i in range(len(y_truth)):\n",
    "        score += 1\n",
    "    accuracy_score = float(score / len(y_truth))\n",
    "    return accuracy_score\n",
    "\n",
    "for c in C:\n",
    "    y_predicted_train, y_predicted_test = prediction(K_train, K_test, c)\n",
    "    training_scores.append(score(y_predicted_train, y_train))\n",
    "    test_scores.append(score(y_predicted_test, y_test))\n",
    "    \n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(str(C), training_scores, \"-ob\", markersize=4, label='training')\n",
    "plt.plot(str(C), test_scores, \"-or\", markersize=4, label='test')\n",
    "plt.xlabel(\"Regularization parameter (C)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
